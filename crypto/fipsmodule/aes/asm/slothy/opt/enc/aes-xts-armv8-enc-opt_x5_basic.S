// The following xts encrypt is from MacBook M3 build folder
// after moving around some instructions

#if !defined(__has_feature)
#define __has_feature(x) 0
#endif
#if __has_feature(memory_sanitizer) && !defined(OPENSSL_NO_ASM)
#define OPENSSL_NO_ASM
#endif

#include <openssl/asm_base.h>

#if !defined(OPENSSL_NO_ASM) && defined(__AARCH64EL__)
#if defined(__ELF__)
#include <openssl/boringssl_prefix_symbols_asm.h>
#include <openssl/arm_arch.h>
.arch   armv8-a+crypto
.text
.globl  aes_hw_slothy_xts_encrypt
.hidden aes_hw_slothy_xts_encrypt
.type   aes_hw_slothy_xts_encrypt,%function
#elif defined(__APPLE__)
#if defined(BORINGSSL_PREFIX)
#include <boringssl_prefix_symbols_asm.h>
#endif
#include <openssl/arm_arch.h>
.text
.globl	_aes_hw_slothy_xts_encrypt
.private_extern	_aes_hw_slothy_xts_encrypt
#else
#error Unknown configuration
#endif

#if __ARM_MAX_ARCH__ >= 8

.align  4


#define STACK_BASE_VREGS 0
#define STACK_SIZE_VREGS (6*16)

.macro save_vregs
     stp  d8,  d9, [sp, #(STACK_BASE_VREGS + 16*0)]
     stp d10, d11, [sp, #(STACK_BASE_VREGS + 16*1)]
     stp d12, d13, [sp, #(STACK_BASE_VREGS + 16*2)]
        stp d14, d15, [sp, #(STACK_BASE_VREGS + 16*3)]
.endm

.macro save_regs
        stp  x19, x20, [sp, #(STACK_BASE_VREGS + 16*4)]
      stp  x21, x22, [sp, #(STACK_BASE_VREGS + 16*5)]
.endm

.macro restore_vregs
        ldp  d8,  d9, [sp, #(STACK_BASE_VREGS + 16*0)]
        ldp d10, d11, [sp, #(STACK_BASE_VREGS + 16*1)]
        ldp d12, d13, [sp, #(STACK_BASE_VREGS + 16*2)]
        ldp d14, d15, [sp, #(STACK_BASE_VREGS + 16*3)]
.endm

.macro restore_regs
        ldp  x19, x20, [sp, #(STACK_BASE_VREGS + 16*4)]
        ldp  x21, x22, [sp, #(STACK_BASE_VREGS + 16*5)]
.endm

// A single AES round
// Prevent SLOTHY from unfolding because uArchs tend to fuse AESMC+AESE
.macro aesr data, key // @slothy:no-unfold
        aese  \data, \key
        aesmc \data, \data
.endm

.macro tweak lo, hi
        extr  x22, x10, x10, #32
        extr  x10, x10,  x9, #63
        and   w11, w19, w22, asr#31
        eor   x9,  x11,  x9, lsl#1
        fmov  \lo,  x9
        fmov  \hi, x10
.endm

_aes_hw_slothy_xts_encrypt:
aes_hw_slothy_xts_encrypt:
  # AARCH64_VALID_CALL_TARGET

        sub sp, sp, #STACK_SIZE_VREGS
        save_vregs
        save_regs

        cmp   x2, #16 // AES-XTS needs at least one block
        b.lt  Lxts_abort
.align  4
Lxts_enc_big_size:  // Encrypt input size >= 16 bytes
        and  x21, x2, #0xf    // store the tail value of length%16
        and  x2, x2, #-16    // len &= 0x1..110000, now divisible by 16
        subs x2, x2, #16

        // Firstly, encrypt the iv with key2, as the first iv of XEX.
        ldr  w6, [x4,#240]
        ld1  {v0.4s}, [x4], #16
        ld1  {v6.16b}, [x5]
        sub  w6, w6, #2
        ld1  {v1.4s}, [x4], #16

Loop_iv_enc:
        aesr v6.16b, v0.16b
        ld1  {v0.4s}, [x4], #16
        subs w6, w6, #2
        aesr v6.16b, v1.16b
        ld1  {v1.4s}, [x4], #16
        b.gt Loop_iv_enc

        aesr v6.16b, v0.16b
        ld1  {v0.4s}, [x4]
        aese v6.16b, v1.16b
        eor  v6.16b, v6.16b, v0.16b

        // The iv for second block
        // x9- iv(low), x10 - iv(high)
        // the five ivs stored into, v6.16b,v8.16b,v9.16b,v10.16b,v11.16b
        fmov  x9, d6
        fmov  x10, v6.d[1]
        mov   w19, #0x87
        tweak d8, v8.d[1]

        mov x7, x3
        ld1 {v16.4s,v17.4s},[x7], #32         // load key schedule
        ld1 {v12.4s,v13.4s},[x7], #32
        ld1 {v14.4s,v15.4s},[x7], #32
        ld1 {v4.4s,v5.4s},  [x7], #32
        ld1 {v18.4s,v19.4s},[x7], #32
        ld1 {v20.4s,v21.4s},[x7], #32
        ld1 {v22.4s,v23.4s},[x7], #32
        ld1 {v7.4s},        [x7]

// Encryption
Lxts_enc:
        cmp x2, #16
        b.lo Lxts_enc_tail1x   // when input = 1 with tail

        subs  x2,x2,#32           // bias
        b.lo  Lxts_enc_tail2x    // when input size  = 2

        // The iv for third block
        tweak d9,v9.d[1]

        cmp  x2,#16
        b.lo  Lxts_enc_tail3x

        // The iv for fourth block
        tweak d10,v10.d[1]

        subs x2,x2,#32
        b.lo  Lxts_enc_tail4x

        // The iv for fifth block
        tweak d11,v11.d[1]

.align  4
        ldp q3, q24, [x0], #0x50
        eor v24.16B, v24.16B, v8.16B
        aesr v24.16b, v16.16b
        extr x16, x10, x10, #32
        extr x7, x10, x9, #63
        aesr v24.16b, v17.16b
        and w13, w19, w16, asr #31
        eor x15, x13, x9, lsl #1
        eor v2.16B, v3.16B, v6.16B// before encryption, xor with iv
        extr x13, x7, x7, #32
        aesr v24.16b, v12.16b
        extr x17, x7, x15, #63
        aesr v2.16b, v16.16b
        aesr v24.16b, v13.16b
        and w20, w19, w13, asr #31
        aesr v2.16b, v17.16b
        extr x13, x17, x17, #32
        aesr v24.16b, v14.16b
        and w22, w19, w13, asr #31
        aesr v2.16b, v12.16b
        ldp q1, q3, [x0, #-48]
        eor x13, x20, x15, lsl #1
        aesr v24.16b, v15.16b
        aesr v2.16b, v13.16b
        aesr v24.16b, v4.16b
        aesr v2.16b, v14.16b
        aesr v24.16b, v5.16b
        eor v25.16B, v3.16B, v10.16B
        aesr v2.16b, v15.16b
        eor x11, x22, x13, lsl #1
        aesr v25.16b, v16.16b
        aesr v24.16b, v18.16b
        aesr v2.16b, v4.16b
        aesr v25.16b, v17.16b
        aesr v24.16b, v19.16b
        extr x8, x17, x13, #63
        extr x22, x8, x8, #32
        aesr v2.16b, v5.16b
        aesr v24.16b, v20.16b
        aesr v25.16b, v12.16b
        and w20, w19, w22, asr #31
        aesr v2.16b, v18.16b
        eor v26.16B, v1.16B, v9.16B
        aesr v25.16b, v13.16b
        ldr q1, [x0, #-16]
        aesr v24.16b, v21.16b
        aesr v26.16b, v16.16b
        aesr v2.16b, v19.16b
        aesr v25.16b, v14.16b
        aesr v24.16b, v22.16b
        aesr v2.16b, v20.16b
        aesr v26.16b, v17.16b
        aese v24.16b, v23.16b
        aesr v25.16b, v15.16b
        aesr v26.16b, v12.16b
        aesr v2.16b, v21.16b
        aesr v25.16b, v4.16b
        eor v0.16B, v24.16B, v7.16B
        aesr v2.16b, v22.16b
        aesr v26.16b, v13.16b
        aesr v25.16b, v5.16b
        eor v0.16B, v0.16B, v8.16B
        fmov d8, x13
        aesr v26.16b, v14.16b
        aese v2.16b, v23.16b
        sub x2, x2, #80
cbz x2, Loop5x_xts_enc_postamble
Loop5x_xts_enc:
                                            // Instructions:    121
                                            // Expected cycles: 38
                                            // Expected IPC:    3.18
                                            //
                                            // Cycle bound:     38.0
                                            // IPC bound:       3.18
                                            //
                                            // Wall time:     31.04s
                                            // User time:     31.04s
                                            //
                                            // --------- cycle (expected) ---------->
                                            // 0                        25
                                            // |------------------------|------------
        aesr v25.16b, v18.16b               // *.....................................
        extr x6, x8, x11, #63               // *.....................................
        ldp q3, q24, [x0], #0x50            // e.....................................
        eor x12, x20, x11, lsl #1           // .*....................................
        eor v27.16B, v2.16B, v7.16B         // .*....................................
        fmov v8.d[1], x17                   // .*....................................
        aesr v26.16b, v15.16b               // .*....................................
        extr x13, x6, x6, #32               // ..*...................................
        eor v31.16B, v1.16B, v11.16B        // ..*...................................
        aesr v25.16b, v19.16b               // ..*...................................
        eor v1.16B, v27.16B, v6.16B         // ...*..................................
        extr x10, x6, x12, #63              // ...*..................................
        fmov d6, x15                        // ...*..................................
        aesr v26.16b, v4.16b                // ...*..................................
        eor v24.16B, v24.16B, v8.16B        // ....e.................................
        aesr v25.16b, v20.16b               // ....*.................................
        aesr v31.16b, v16.16b               // ....*.................................
        and w13, w19, w13, asr #31          // ....*.................................
        eor x9, x13, x12, lsl #1            // .....*................................
        aesr v26.16b, v5.16b                // .....*................................
        aesr v31.16b, v17.16b               // ......*...............................
        aesr v25.16b, v21.16b               // ......*...............................
        aesr v24.16b, v16.16b               // ......e...............................
        fmov v6.d[1], x7                    // ......*...............................
        extr x16, x10, x10, #32             // ......e...............................
        extr x7, x10, x9, #63               // .......e..............................
        aesr v26.16b, v18.16b               // .......*..............................
        aesr v24.16b, v17.16b               // ........e.............................
        and w13, w19, w16, asr #31          // ........e.............................
        aesr v31.16b, v12.16b               // ........*.............................
        aesr v25.16b, v22.16b               // ........*.............................
        eor x15, x13, x9, lsl #1            // .........e............................
        aesr v26.16b, v19.16b               // .........*............................
        stp q1, q0, [x1], #0x50             // .........*............................
        eor v2.16B, v3.16B, v6.16B          // .........e............................
        aesr v31.16b, v13.16b               // ..........*...........................
        extr x13, x7, x7, #32               // ..........e...........................
        aesr v24.16b, v12.16b               // ..........e...........................
        aese v25.16b, v23.16b               // ..........*...........................
        extr x17, x7, x15, #63              // ...........e..........................
        aesr v26.16b, v20.16b               // ...........*..........................
        aesr v2.16b, v16.16b                // ...........e..........................
        aesr v31.16b, v14.16b               // ............*.........................
        eor v1.16B, v25.16B, v7.16B         // ............*.........................
        aesr v24.16b, v13.16b               // ............e.........................
        and w20, w19, w13, asr #31          // ............e.........................
        aesr v2.16b, v17.16b                // .............e........................
        extr x13, x17, x17, #32             // .............e........................
        aesr v26.16b, v21.16b               // .............*........................
        aesr v24.16b, v14.16b               // ..............e.......................
        eor v30.16B, v1.16B, v10.16B        // ..............*.......................
        aesr v31.16b, v15.16b               // ..............*.......................
        fmov d10, x12                       // ..............*.......................
        and w22, w19, w13, asr #31          // ..............e.......................
        aesr v2.16b, v12.16b                // ...............e......................
        ldp q1, q3, [x0, #-48]              // ...............e......................
        aesr v26.16b, v22.16b               // ...............*......................
        eor x13, x20, x15, lsl #1           // ...............e......................
        aesr v31.16b, v4.16b                // ................*.....................
        aesr v24.16b, v15.16b               // ................e.....................
        aesr v2.16b, v13.16b                // .................e....................
        aese v26.16b, v23.16b               // .................*....................
        fmov v10.d[1], x6                   // .................*....................
        aesr v24.16b, v4.16b                // ..................e...................
        aesr v31.16b, v5.16b                // ..................*...................
        aesr v2.16b, v14.16b                // ...................e..................
        eor v27.16B, v26.16B, v7.16B        // ...................*..................
        aesr v31.16b, v18.16b               // ....................*.................
        aesr v24.16b, v5.16b                // ....................e.................
        eor v25.16B, v3.16B, v10.16B        // ....................e.................
        aesr v2.16b, v15.16b                // .....................e................
        eor v26.16B, v27.16B, v9.16B        // .....................*................
        fmov d9, x11                        // .....................*................
        eor x11, x22, x13, lsl #1           // .....................e................
        aesr v25.16b, v16.16b               // ......................e...............
        aesr v31.16b, v19.16b               // ......................*...............
        aesr v24.16b, v18.16b               // ......................e...............
        aesr v2.16b, v4.16b                 // .......................e..............
        stp q26, q30, [x1, #-48]            // .......................*..............
        aesr v25.16b, v17.16b               // ........................e.............
        aesr v31.16b, v20.16b               // ........................*.............
        fmov v9.d[1], x8                    // ........................*.............
        aesr v24.16b, v19.16b               // ........................e.............
        extr x8, x17, x13, #63              // ........................e.............
        extr x22, x8, x8, #32               // .........................e............
        aesr v2.16b, v5.16b                 // .........................e............
        aesr v31.16b, v21.16b               // ..........................*...........
        aesr v24.16b, v20.16b               // ..........................e...........
        aesr v25.16b, v12.16b               // ..........................e...........
        and w20, w19, w22, asr #31          // ..........................e...........
        aesr v2.16b, v18.16b                // ...........................e..........
        eor v26.16B, v1.16B, v9.16B         // ...........................e..........
        aesr v25.16b, v13.16b               // ............................e.........
        aesr v31.16b, v22.16b               // ............................*.........
        ldr q1, [x0, #-16]                  // ............................e.........
        aesr v24.16b, v21.16b               // ............................e.........
        aesr v26.16b, v16.16b               // .............................e........
        aesr v2.16b, v19.16b                // .............................e........
        aesr v25.16b, v14.16b               // ..............................e.......
        aese v31.16b, v23.16b               // ..............................*.......
        aesr v24.16b, v22.16b               // ..............................e.......
        aesr v2.16b, v20.16b                // ...............................e......
        aesr v26.16b, v17.16b               // ...............................e......
        aese v24.16b, v23.16b               // ................................e.....
        eor v3.16B, v31.16B, v7.16B         // ................................*.....
        aesr v25.16b, v15.16b               // ................................e.....
        aesr v26.16b, v12.16b               // .................................e....
        aesr v2.16b, v21.16b                // .................................e....
        eor v27.16B, v3.16B, v11.16B        // ..................................*...
        fmov d11, x9                        // ..................................*...
        aesr v25.16b, v4.16b                // ..................................e...
        eor v0.16B, v24.16B, v7.16B         // ..................................e...
        aesr v2.16b, v22.16b                // ...................................e..
        aesr v26.16b, v13.16b               // ...................................e..
        aesr v25.16b, v5.16b                // ....................................e.
        eor v0.16B, v0.16B, v8.16B          // ....................................e.
        fmov d8, x13                        // ....................................e.
        aesr v26.16b, v14.16b               // .....................................e
        aese v2.16b, v23.16b                // .....................................e
        str q27, [x1, #-16]                 // .....................................*
        fmov v11.d[1], x10                  // .....................................*

                                                    // ---------------------------- cycle (expected) ----------------------------->
                                                    // 0                        25                       50
                                                    // |------------------------|------------------------|-------------------------
        // ldp q0, q1, [x0], #0x50                  // e.....................................~.....................................
        // ldp q24, q25, [x0, #-0x30]               // ...............e......................'..............~......................
        // ldr q26, [x0, #-0x10]                    // ............................e.........'...........................~.........
        // eor  v0.16b,v0.16b,v6.16b                // .........e............................'........~............................
        // eor  v1.16b,v1.16b,v8.16b                // ....e.................................'...~.................................
        // eor  v24.16b,v24.16b,v9.16b              // ...........................e..........'..........................~..........
        // eor  v25.16b,v25.16b,v10.16b             // ....................e.................'...................~.................
        // eor  v26.16b,v26.16b,v11.16b             // ..~...................................'.*...................................
        // aesr    v0.16b, v16.16b                  // ...........e..........................'..........~..........................
        // aesr    v1.16b, v16.16b                  // ......e...............................'.....~...............................
        // aesr    v24.16b, v16.16b                 // .............................e........'............................~........
        // aesr    v25.16b, v16.16b                 // ......................e...............'.....................~...............
        // aesr    v26.16b, v16.16b                 // ....~.................................'...*.................................
        // aesr    v0.16b, v17.16b                  // .............e........................'............~........................
        // aesr    v1.16b, v17.16b                  // ........e.............................'.......~.............................
        // aesr    v24.16b, v17.16b                 // ...............................e......'..............................~......
        // aesr    v25.16b, v17.16b                 // ........................e.............'.......................~.............
        // aesr    v26.16b, v17.16b                 // ......~...............................'.....*...............................
        // aesr    v0.16b, v12.16b                  // ...............e......................'..............~......................
        // aesr    v1.16b, v12.16b                  // ..........e...........................'.........~...........................
        // aesr    v24.16b, v12.16b                 // .................................e....'................................~....
        // aesr    v25.16b, v12.16b                 // ..........................e...........'.........................~...........
        // aesr    v26.16b, v12.16b                 // ........~.............................'.......*.............................
        // aesr    v0.16b, v13.16b                  // .................e....................'................~....................
        // aesr    v1.16b, v13.16b                  // ............e.........................'...........~.........................
        // aesr    v24.16b, v13.16b                 // ...................................e..'..................................~..
        // aesr    v25.16b, v13.16b                 // ............................e.........'...........................~.........
        // aesr    v26.16b, v13.16b                 // ..........~...........................'.........*...........................
        // aesr    v0.16b, v14.16b                  // ...................e..................'..................~..................
        // aesr    v1.16b, v14.16b                  // ..............e.......................'.............~.......................
        // aesr    v24.16b, v14.16b                 // .....................................e'.....................................
        // aesr    v25.16b, v14.16b                 // ..............................e.......'.............................~.......
        // aesr    v26.16b, v14.16b                 // ............~.........................'...........*.........................
        // aesr    v0.16b, v15.16b                  // .....................e................'....................~................
        // aesr    v1.16b, v15.16b                  // ................e.....................'...............~.....................
        // aesr    v24.16b, v15.16b                 // .~....................................'*....................................
        // aesr    v25.16b, v15.16b                 // ................................e.....'...............................~.....
        // aesr    v26.16b, v15.16b                 // ..............~.......................'.............*.......................
        // aesr    v0.16b, v4.16b                   // .......................e..............'......................~..............
        // aesr    v1.16b, v4.16b                   // ..................e...................'.................~...................
        // aesr    v24.16b, v4.16b                  // ...~..................................'..*..................................
        // aesr    v25.16b, v4.16b                  // ..................................e...'.................................~...
        // aesr    v26.16b, v4.16b                  // ................~.....................'...............*.....................
        // aesr    v0.16b, v5.16b                   // .........................e............'........................~............
        // aesr    v1.16b, v5.16b                   // ....................e.................'...................~.................
        // aesr    v24.16b, v5.16b                  // .....~................................'....*................................
        // aesr    v25.16b, v5.16b                  // ....................................e.'...................................~.
        // aesr    v26.16b, v5.16b                  // ..................~...................'.................*...................
        // aesr    v0.16b, v18.16b                  // ...........................e..........'..........................~..........
        // aesr    v1.16b, v18.16b                  // ......................e...............'.....................~...............
        // aesr    v24.16b, v18.16b                 // .......~..............................'......*..............................
        // aesr    v25.16b, v18.16b                 // ~.....................................*.....................................
        // aesr    v26.16b, v18.16b                 // ....................~.................'...................*.................
        // aesr    v0.16b, v19.16b                  // .............................e........'............................~........
        // aesr    v1.16b, v19.16b                  // ........................e.............'.......................~.............
        // aesr    v24.16b, v19.16b                 // .........~............................'........*............................
        // aesr    v25.16b, v19.16b                 // ..~...................................'.*...................................
        // aesr    v26.16b, v19.16b                 // ......................~...............'.....................*...............
        // aesr    v0.16b, v20.16b                  // ...............................e......'..............................~......
        // aesr    v1.16b, v20.16b                  // ..........................e...........'.........................~...........
        // aesr    v24.16b, v20.16b                 // ...........~..........................'..........*..........................
        // aesr    v25.16b, v20.16b                 // ....~.................................'...*.................................
        // aesr    v26.16b, v20.16b                 // ........................~.............'.......................*.............
        // aesr    v0.16b, v21.16b                  // .................................e....'................................~....
        // aesr    v1.16b, v21.16b                  // ............................e.........'...........................~.........
        // aesr    v24.16b, v21.16b                 // .............~........................'............*........................
        // aesr    v25.16b, v21.16b                 // ......~...............................'.....*...............................
        // aesr    v26.16b, v21.16b                 // ..........................~...........'.........................*...........
        // aesr    v0.16b, v22.16b                  // ...................................e..'..................................~..
        // aesr    v1.16b, v22.16b                  // ..............................e.......'.............................~.......
        // aesr    v24.16b, v22.16b                 // ...............~......................'..............*......................
        // aesr    v25.16b, v22.16b                 // ........~.............................'.......*.............................
        // aesr    v26.16b, v22.16b                 // ............................~.........'...........................*.........
        // aese  v0.16b,v23.16b                     // .....................................e'.....................................
        // aese  v1.16b,v23.16b                     // ................................e.....'...............................~.....
        // aese  v24.16b,v23.16b                    // .................~....................'................*....................
        // aese  v25.16b,v23.16b                    // ..........~...........................'.........*...........................
        // aese  v26.16b,v23.16b                    // ..............................~.......'.............................*.......
        // eor  v0.16b,v0.16b,v7.16b                // .~....................................'*....................................
        // eor  v0.16b,v0.16b,v6.16b                // ...~..................................'..*..................................
        // extr  x22, x10, x10, #32                 // ......e...............................'.....~...............................
        // extr  x10, x10,  x9, #63                 // .......e..............................'......~..............................
        // and   w11, w19, w22, asr#31              // ........e.............................'.......~.............................
        // eor   x9,  x11,  x9, lsl#1               // .........e............................'........~............................
        // fmov  d6,  x9                            // ...~..................................'..*..................................
        // fmov  v6.d[1], x10                       // ......~...............................'.....*...............................
        // eor  v1.16b,v1.16b,v7.16b                // ..................................e...'.................................~...
        // eor  v1.16b,v1.16b,v8.16b                // ....................................e.'...................................~.
        // extr  x22, x10, x10, #32                 // ..........e...........................'.........~...........................
        // extr  x10, x10,  x9, #63                 // ...........e..........................'..........~..........................
        // and   w11, w19, w22, asr#31              // ............e.........................'...........~.........................
        // eor   x9,  x11,  x9, lsl#1               // ...............e......................'..............~......................
        // fmov  d8,  x9                            // ....................................e.'...................................~.
        // fmov  v8.d[1], x10                       // .~....................................'*....................................
        // eor  v24.16b,v24.16b,v7.16b              // ...................~..................'..................*..................
        // eor  v24.16b,v24.16b,v9.16b              // .....................~................'....................*................
        // extr  x22, x10, x10, #32                 // .............e........................'............~........................
        // extr  x10, x10,  x9, #63                 // ........................e.............'.......................~.............
        // and   w11, w19, w22, asr#31              // ..............e.......................'.............~.......................
        // eor   x9,  x11,  x9, lsl#1               // .....................e................'....................~................
        // fmov  d9,  x9                            // .....................~................'....................*................
        // fmov  v9.d[1], x10                       // ........................~.............'.......................*.............
        // eor  v25.16b,v25.16b,v7.16b              // ............~.........................'...........*.........................
        // eor  v25.16b,v25.16b,v10.16b             // ..............~.......................'.............*.......................
        // extr  x22, x10, x10, #32                 // .........................e............'........................~............
        // extr  x10, x10,  x9, #63                 // ~.....................................*.....................................
        // and   w11, w19, w22, asr#31              // ..........................e...........'.........................~...........
        // eor   x9,  x11,  x9, lsl#1               // .~....................................'*....................................
        // fmov  d10,  x9                           // ..............~.......................'.............*.......................
        // fmov  v10.d[1], x10                      // .................~....................'................*....................
        // eor  v26.16b,v26.16b,v7.16b              // ................................~.....'...............................*.....
        // eor  v26.16b,v26.16b,v11.16b             // ..................................~...'.................................*...
        // extr  x22, x10, x10, #32                 // ..~...................................'.*...................................
        // extr  x10, x10,  x9, #63                 // ...~..................................'..*..................................
        // and   w11, w19, w22, asr#31              // ....~.................................'...*.................................
        // eor   x9,  x11,  x9, lsl#1               // .....~................................'....*................................
        // fmov  d11,  x9                           // ..................................~...'.................................*...
        // fmov  v11.d[1], x10                      // .....................................~'....................................*
        // stp q0, q1, [x1], #0x50                  // .........~............................'........*............................
        // stp q24, q25, [x1, #-0x30]               // .......................~..............'......................*..............
        // str q26, [x1, #-0x10]                    // .....................................~'....................................*

        subs x2, x2, #0x50
        b.hs Loop5x_xts_enc
Loop5x_xts_enc_postamble:// end of loop kernel
        aesr v25.16b, v18.16b
        extr x6, x8, x11, #63
        eor x12, x20, x11, lsl #1
        eor v27.16B, v2.16B, v7.16B
        fmov v8.d[1], x17
        aesr v26.16b, v15.16b
        extr x13, x6, x6, #32
        eor v31.16B, v1.16B, v11.16B
        aesr v25.16b, v19.16b
        eor v1.16B, v27.16B, v6.16B
        extr x10, x6, x12, #63
        fmov d6, x15
        aesr v26.16b, v4.16b
        aesr v25.16b, v20.16b
        aesr v31.16b, v16.16b
        and w13, w19, w13, asr #31
        eor x9, x13, x12, lsl #1
        aesr v26.16b, v5.16b
        aesr v31.16b, v17.16b
        aesr v25.16b, v21.16b
        fmov v6.d[1], x7
        aesr v26.16b, v18.16b
        aesr v31.16b, v12.16b
        aesr v25.16b, v22.16b
        aesr v26.16b, v19.16b
        stp q1, q0, [x1], #0x50
        aesr v31.16b, v13.16b
        aese v25.16b, v23.16b
        aesr v26.16b, v20.16b
        aesr v31.16b, v14.16b
        eor v1.16B, v25.16B, v7.16B
        aesr v26.16b, v21.16b
        eor v30.16B, v1.16B, v10.16B
        aesr v31.16b, v15.16b
        fmov d10, x12
        aesr v26.16b, v22.16b
        aesr v31.16b, v4.16b
        aese v26.16b, v23.16b
        fmov v10.d[1], x6
        aesr v31.16b, v5.16b
        eor v27.16B, v26.16B, v7.16B
        aesr v31.16b, v18.16b
        eor v26.16B, v27.16B, v9.16B
        fmov d9, x11
        aesr v31.16b, v19.16b
        stp q26, q30, [x1, #-48]
        aesr v31.16b, v20.16b
        fmov v9.d[1], x8
        aesr v31.16b, v21.16b
        aesr v31.16b, v22.16b
        aese v31.16b, v23.16b
        eor v3.16B, v31.16B, v7.16B
        eor v27.16B, v3.16B, v11.16B
        fmov d11, x9
        str q27, [x1, #-16]
        fmov v11.d[1], x10
        b Loop5x_xts_enc_end
Loop5x_xts_enc_end:

Loop5x_enc_after:
        cmn  x2,#0x10
        b.eq  Lxts_enc_tail4x  // 4 blocks left

        add  x2,x2,#0x50
        cbz  x2,Lxts_enc_done     // no blocks left

        subs  x2,x2,#0x20
        b.lo  Lxts_enc_tail1x    // 1 block left

        subs x2,x2,#0x10
        b.lo Lxts_enc_tail2x  // 2 blocks left

        b  Lxts_enc_tail3x  // 3 blocks left

.align  4
Lxts_enc_tail4x:
        ld1  {v0.16b}, [x0],#16              // the first block
        ld1  {v1.16b}, [x0],#16  // the second block
        ld1  {v24.16b},[x0],#16 // the third block
        ld1  {v25.16b},[x0],#16  // the fourth block

        eor  v0.16b,v0.16b,v6.16b
        eor  v1.16b,v1.16b,v8.16b
        eor  v24.16b,v24.16b,v9.16b
        eor  v25.16b,v25.16b,v10.16b

        aesr    v0.16b, v16.16b
        aesr    v1.16b, v16.16b
        aesr    v24.16b, v16.16b
        aesr    v25.16b, v16.16b

        aesr    v0.16b, v17.16b
        aesr    v1.16b, v17.16b
        aesr    v24.16b, v17.16b
        aesr    v25.16b, v17.16b

        aesr    v0.16b, v12.16b
        aesr    v1.16b, v12.16b
        aesr    v24.16b, v12.16b
        aesr    v25.16b, v12.16b

        aesr    v0.16b, v13.16b
        aesr    v1.16b, v13.16b
        aesr    v24.16b, v13.16b
        aesr    v25.16b, v13.16b

        aesr    v0.16b, v14.16b
        aesr    v1.16b, v14.16b
        aesr    v24.16b, v14.16b
        aesr    v25.16b, v14.16b

        aesr    v0.16b, v15.16b
        aesr    v1.16b, v15.16b
        aesr    v24.16b, v15.16b
        aesr    v25.16b, v15.16b

        aesr    v0.16b, v4.16b
        aesr    v1.16b, v4.16b
        aesr    v24.16b, v4.16b
        aesr    v25.16b, v4.16b

        aesr    v0.16b, v5.16b
        aesr    v1.16b, v5.16b
        aesr    v24.16b, v5.16b
        aesr    v25.16b, v5.16b

        aesr    v0.16b, v18.16b
        aesr    v1.16b, v18.16b
        aesr    v24.16b, v18.16b
        aesr    v25.16b, v18.16b

        aesr    v0.16b, v19.16b
        aesr    v1.16b, v19.16b
        aesr    v24.16b, v19.16b
        aesr    v25.16b, v19.16b

        aesr    v0.16b, v20.16b
        aesr    v1.16b, v20.16b
        aesr    v24.16b, v20.16b
        aesr    v25.16b, v20.16b

        aesr    v0.16b, v21.16b
        aesr    v1.16b, v21.16b
        aesr    v24.16b, v21.16b
        aesr    v25.16b, v21.16b

        aesr    v0.16b, v22.16b
        aesr    v1.16b, v22.16b
        aesr    v24.16b, v22.16b
        aesr    v25.16b, v22.16b

        aese  v0.16b,v23.16b
        aese  v1.16b,v23.16b
        aese  v24.16b,v23.16b
        aese  v25.16b,v23.16b

        eor  v0.16b,v0.16b,v7.16b
        eor  v0.16b,v0.16b,v6.16b

        eor  v1.16b,v1.16b,v7.16b
        eor  v1.16b,v1.16b,v8.16b

        eor  v24.16b,v24.16b,v7.16b
        eor  v24.16b,v24.16b,v9.16b

        eor  v25.16b,v25.16b,v7.16b
        eor  v25.16b,v25.16b,v10.16b

        st1  {v0.16b,v1.16b},[x1],#32
        st1  {v24.16b,v25.16b},[x1],#32

        // The iv for tail
        fmov  x9,d10
        fmov  x10,v10.d[1]
        tweak d6,v6.d[1]

        b  Lxts_enc_done

.align  4
Lxts_enc_tail3x:
        ld1  {v0.16b,v1.16b}, [x0],#32
        ld1  {v24.16b}, [x0],#16

        eor  v0.16b,v0.16b,v6.16b
        eor  v1.16b,v1.16b,v8.16b
        eor  v24.16b,v24.16b,v9.16b

        // First round with v16
        aesr    v0.16b, v16.16b
        aesr    v1.16b, v16.16b
        aesr    v24.16b, v16.16b

        // Second round with v17
        aesr    v0.16b, v17.16b
        aesr    v1.16b, v17.16b
        aesr    v24.16b, v17.16b

        // Third round with v12
        aesr    v0.16b, v12.16b
        aesr    v1.16b, v12.16b
        aesr    v24.16b, v12.16b

        // Fourth round with v13
        aesr    v0.16b, v13.16b
        aesr    v1.16b, v13.16b
        aesr    v24.16b, v13.16b

        // Fifth round with v14
        aesr    v0.16b, v14.16b
        aesr    v1.16b, v14.16b
        aesr    v24.16b, v14.16b

        // Sixth round with v15
        aesr    v0.16b, v15.16b
        aesr    v1.16b, v15.16b
        aesr    v24.16b, v15.16b

        // Seventh round with v4
        aesr    v0.16b, v4.16b
        aesr    v1.16b, v4.16b
        aesr    v24.16b, v4.16b

        // Eighth round with v5
        aesr    v0.16b, v5.16b
        aesr    v1.16b, v5.16b
        aesr    v24.16b, v5.16b

        // 9th round with v18
        aesr    v0.16b, v18.16b
        aesr    v1.16b, v18.16b
        aesr    v24.16b, v18.16b

        // 10th round with v19
        aesr    v0.16b, v19.16b
        aesr    v1.16b, v19.16b
        aesr    v24.16b, v19.16b

        aesr    v0.16b, v20.16b
        aesr    v1.16b, v20.16b
        aesr    v24.16b, v20.16b

        aesr    v0.16b, v21.16b
        aesr    v1.16b, v21.16b
        aesr    v24.16b, v21.16b

        aesr    v0.16b, v22.16b
        aesr    v1.16b, v22.16b
        aesr    v24.16b, v22.16b

        aese  v0.16b,v23.16b
        aese  v1.16b,v23.16b
        aese  v24.16b,v23.16b

        eor  v0.16b,v0.16b,v7.16b
        eor  v0.16b,v0.16b,v6.16b
        eor  v1.16b,v1.16b,v7.16b
        eor  v1.16b,v1.16b,v8.16b
        eor  v24.16b,v24.16b,v7.16b
        eor  v24.16b,v24.16b,v9.16b

        st1  {v0.16b,v1.16b},[x1],#32
        st1  {v24.16b},[x1],#16

        // The iv for tail
        fmov  x9,d9
        fmov  x10,v9.d[1]
        tweak d6,v6.d[1]

        b Lxts_enc_done  // done processing three blocks

Lxts_enc_tail2x:
        ld1  {v0.16b,v1.16b},[x0],#32  // the first block

        eor  v0.16b,v0.16b,v6.16b
        eor  v1.16b,v1.16b,v8.16b

        // First round with v16
        aesr    v0.16b, v16.16b
        aesr    v1.16b, v16.16b

        // Second round with v17
        aesr    v0.16b, v17.16b
        aesr    v1.16b, v17.16b

        // Third round with v12
        aesr    v0.16b, v12.16b
        aesr    v1.16b, v12.16b

        // Fourth round with v13
        aesr    v0.16b, v13.16b
        aesr    v1.16b, v13.16b

        // Fifth round with v14
        aesr    v0.16b, v14.16b
        aesr    v1.16b, v14.16b

        // Sixth round with v15
        aesr    v0.16b, v15.16b
        aesr    v1.16b, v15.16b

        // Seventh round with v4
        aesr    v0.16b, v4.16b
        aesr    v1.16b, v4.16b

        // Eighth round with v5
        aesr    v0.16b, v5.16b
        aesr    v1.16b, v5.16b

        // 9th round with v18
        aesr    v0.16b, v18.16b
        aesr    v1.16b, v18.16b

        // 10th round with v19
        aesr    v0.16b, v19.16b
        aesr    v1.16b, v19.16b

        aesr    v0.16b, v20.16b
        aesr    v1.16b, v20.16b

        aesr    v0.16b, v21.16b
        aesr    v1.16b, v21.16b

        aesr    v0.16b, v22.16b
        aesr    v1.16b, v22.16b

        aese  v0.16b,v23.16b
        aese  v1.16b,v23.16b

        eor  v0.16b,v0.16b,v7.16b
        eor  v0.16b,v0.16b,v6.16b
        eor  v1.16b,v1.16b,v7.16b
        eor  v1.16b,v1.16b,v8.16b

        st1  {v0.16b,v1.16b},[x1],#32

        // The iv for tail
        fmov  x9,d8
        fmov  x10,v8.d[1]
        tweak d6,v6.d[1]
        b  Lxts_enc_done

Lxts_enc_tail1x:
        ld1  {v0.16b}, [x0],#16  // the first block

        eor  v0.16b,v0.16b,v6.16b

        // First round with v16
        aesr    v0.16b, v16.16b

        // Second round with v17
        aesr    v0.16b, v17.16b

        // Third round with v12
        aesr    v0.16b, v12.16b

        // Fourth round with v13
        aesr    v0.16b, v13.16b

        // Fifth round with v14
        aesr    v0.16b, v14.16b

        // Sixth round with v15
        aesr    v0.16b, v15.16b

        // Seventh round with v4
        aesr    v0.16b, v4.16b

        // Eighth round with v5
        aesr    v0.16b, v5.16b

        // 9th round with v18
        aesr    v0.16b, v18.16b

        // 10th round with v19
        aesr    v0.16b, v19.16b

        aesr    v0.16b, v20.16b
        aesr    v0.16b, v21.16b
        aesr    v0.16b, v22.16b
        aese  v0.16b,v23.16b

        eor  v0.16b,v0.16b,v7.16b
        eor  v0.16b,v0.16b,v6.16b
        st1  {v0.16b},[x1],#16

        // tweak for tail
        fmov  x9,d6
        fmov  x10,v6.d[1]
        tweak d6,v6.d[1]
        b  Lxts_enc_done

.align  5
Lxts_enc_done:
        // Process the tail block with cipher stealing.
        tst  x21,#0xf
        b.eq  Lxts_abort

        mov  x20,x0
        mov  x13,x1
        sub  x1,x1,#16
.composite_enc_loop:
        subs  x21,x21,#1
        ldrb  w15,[x1,x21]
        ldrb  w14,[x20,x21]
        strb  w15,[x13,x21]
        strb  w14,[x1,x21]
        b.gt  .composite_enc_loop
Lxts_enc_load_done:
        ld1  {v26.16b},[x1]
        eor  v26.16b,v26.16b,v6.16b

        // Encrypt the composite block to get the last second encrypted text block
        ldr  w6,[x3,#240]        // load key schedule...
        ld1  {v0.16b},[x3],#16
        sub  w6,w6,#2
        ld1  {v1.16b},[x3],#16     // load key schedule...
Loop_final_enc:
        aesr    v26.16b, v0.16b
        ld1  {v0.4s},[x3],#16
        subs  w6,w6,#2
        aesr    v26.16b, v1.16b
        ld1  {v1.4s},[x3],#16
        b.gt  Loop_final_enc

        aesr    v26.16b, v0.16b
        ld1  {v0.4s},[x3]
        aese  v26.16b,v1.16b
        eor  v26.16b,v26.16b,v0.16b
        eor  v26.16b,v26.16b,v6.16b
        st1  {v26.16b},[x1]

Lxts_abort:
        restore_regs

Lxts_enc_final_abort:
        restore_vregs
        add sp, sp, #STACK_SIZE_VREGS
        ret

#endif
#endif  // !OPENSSL_NO_ASM && defined(__AARCH64EL__) && defined(__APPLE__)
#if defined(__ELF__)
// See https: // www.airs.com/blog/archives/518.
.section .note.GNU-stack,"",%progbits
#endif
